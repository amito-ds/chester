Full report to analyze my data:

Data information:
Data Information Report
Problem Type: Regression
Target Variable: target
Feature Types: {'numeric': ['age', 'educ', 'black', 'hispan', 'married', 'nodegree'], 'boolean': [], 'text': [], 'categorical': [], 'time': [], 'id': []}
Loss Function: R squared
Evaluation Metrics: ['R2', 'MSE', 'MAE', 'MAPE']
Optional Models: {'baseline-average', 'linear', 'baseline-median', 'catboost'}


features engineering process for the data:
** model pre analysis report:
Feature stats:
            col # unique # missing       max        min      avg      std  \
0  target_label      457         0  60307.93  -25564.67  -2966.8  9654.71   

               CI  median           top_vals           bottom_vals  
0  (-3608, -2326)  -752.9  60308,36647,34099  -25565,-25514,-25049  

Training models and choosing the best one
Model results compared - showing the best out of each type after CV & HP tuning: 
+-------+-----------------------+--------------------+---------------------+--------------------------------+
|  type |         model         | mean_squared_error | mean_absolute_error | mean_absolute_percentage_error |
+-------+-----------------------+--------------------+---------------------+--------------------------------+
|  test |     BaselineModel     | 89846296.95756996  |  6846.627933049827  |     3.1594085889594296e+18     |
|  test |     CatboostModel     | 76051515.80025382  |  6447.858446216671  |     5.576630304359106e+18      |
|  test | LinearRegressionModel | 72936336.47256535  |   6223.28990741922  |     4.701496291132721e+18      |
| train |     BaselineModel     | 89668074.84290396  |  6838.579663168474  |     3.159031672959326e+18      |
| train |     CatboostModel     | 44235856.59508495  |  4786.112232049477  |     3.6659973868694743e+18     |
| train | LinearRegressionModel | 69397283.25316183  |  6064.068578774037  |     4.536961176812934e+18      |
+-------+-----------------------+--------------------+---------------------+--------------------------------+


Post model analysis - analyzing results of the chosen model: 
Learning curve by training examples
+-------------+---------------------+----------------------+----------------------+---------------------+
| train_sizes |  train_scores_mean  |   train_scores_std   |   test_scores_mean   |   test_scores_std   |
+-------------+---------------------+----------------------+----------------------+---------------------+
|      39     |  0.4917739067995794 | 0.061921721468534675 | -0.06459637066777002 | 0.16850311191225265 |
|     127     |  0.3210007947399293 | 0.02826498926629389  |  0.1380609037812982  |  0.0728017479388756 |
|     215     | 0.26636588892882707 | 0.020006245737093222 | 0.15623378145839203  |  0.0746482668037361 |
|     303     | 0.23620899870864145 | 0.012255561512376972 | 0.16711227787981536  | 0.05133671148823514 |
|     392     | 0.22582425526569957 | 0.010081281301168626 |  0.1805857275249126  |  0.0539872451257407 |
+-------------+---------------------+----------------------+----------------------+---------------------+


Boostrap metrics, sample 20 results:
+--------------------+---------------------+--------------------------------+
| mean_squared_error | mean_absolute_error | mean_absolute_percentage_error |
+--------------------+---------------------+--------------------------------+
| 102607521.38672434 |   7596.8927331117   |     4.853597429879146e+18      |
| 90307111.23960562  |   7481.57955081777  |     6.424201947282576e+18      |
| 106598963.35452072 |  7792.747800558192  |     4.686118949726691e+18      |
| 87957731.71604049  |  7300.026545080821  |     5.884296488600908e+18      |
| 103556991.59953193 |  7572.392190340411  |     5.213359896421922e+18      |
| 77764652.15997571  |  6934.917096366824  |     5.440411207462851e+18      |
| 87957611.91636492  |  7067.166085163928  |     5.469987798714391e+18      |
| 95665518.25480565  |  7452.411868960052  |     5.074450247069847e+18      |
| 73176146.04140574  |  6635.3875917044725 |     5.135284907632511e+18      |
| 90101866.10339317  |  7262.2752386593465 |     4.469768011367261e+18      |
| 74178262.37846267  |  6790.698469626638  |     5.053068985023818e+18      |
| 106778966.53488167 |  8137.512599937669  |     5.594664899399998e+18      |
| 117060899.79785919 |  8427.030182287614  |     3.939855910234695e+18      |
| 81195579.04618147  |  7162.327115650652  |     4.924503539673131e+18      |
| 83512509.54980573  |  7095.427399228802  |     6.064694400426498e+18      |
| 71990352.27080277  |  6685.029042950707  |     6.252669756518286e+18      |
| 96141170.10082714  |   7642.97982525114  |     7.106576670487627e+18      |
|  86249725.9476676  |  7327.831967411523  |     6.226501133110089e+18      |
| 107165959.04328822 |  7907.537139903805  |     3.700597495014974e+18      |
| 69141607.34610604  |  6311.143091749109  |     5.446097452128089e+18      |
+--------------------+---------------------+--------------------------------+

