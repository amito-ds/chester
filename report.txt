Full report to analyze my data:

Data information:
Data Information Report
Problem Type: Regression
Target Variable: target
Feature Types: {'numeric': [], 'boolean': [], 'text': [], 'categorical': ['landing_page'], 'time': [], 'id': []}
Loss Function: R squared
Evaluation Metrics: ['R2', 'MSE', 'MAE', 'MAPE']
Optional Models: {'baseline-average', 'linear', 'baseline-median', 'catboost'}


features engineering process for the data:
** model pre analysis report:
Feature stats:
            col # unique # missing  max   min    avg   std            CI  \
0  target_label        3         0  1.0  -1.0  -0.01  0.34  (-0.01, 0.0)   

  median      top_vals   bottom_vals  
0    0.0  1.0,0.0,-1.0  -1.0,0.0,1.0  

top 50 with lowest partial pvalue for categorical feat based on chi square:
[('landing_page', 9.036951353011947e-120)]

Training models and choosing the best one
Model results compared - showing the best out of each type after CV & HP tuning: 
+-------+-----------------------+---------------------+---------------------+--------------------------------+
|  type |         model         |  mean_squared_error | mean_absolute_error | mean_absolute_percentage_error |
+-------+-----------------------+---------------------+---------------------+--------------------------------+
|  test |     BaselineModel     |        0.121        |        0.121        |             0.121              |
|  test |     CatboostModel     | 0.10719830800981552 | 0.21088536899423888 |       467279844823251.3        |
|  test | LinearRegressionModel | 0.11045859239782974 |  0.1674458872176558 |       241316900626339.75       |
| train |     BaselineModel     |        0.121        |        0.121        |             0.121              |
| train |     CatboostModel     | 0.10705297462043202 | 0.21075475677132988 |       467031296451814.2        |
| train | LinearRegressionModel |  0.110309737822243  | 0.16732645829300502 |       241124997198492.4        |
+-------+-----------------------+---------------------+---------------------+--------------------------------+


Post model analysis - analyzing results of the chosen model: 
Top 100 Feature importance (in %, 100 = the most important one):
{'index_landing_page': 100}

Learning curve by training examples
+-------------+---------------------+-----------------------+---------------------+----------------------+
| train_sizes |  train_scores_mean  |    train_scores_std   |   test_scores_mean  |   test_scores_std    |
+-------------+---------------------+-----------------------+---------------------+----------------------+
|     320     | 0.11802618231416914 | 0.0070631496643028145 | 0.10368400006715098 | 0.00904131587392641  |
|     1040    | 0.11398262389024019 |  0.00404587879397392  | 0.11065975746159921 | 0.007383806735046203 |
|     1760    | 0.11805291060177632 |  0.003309725545002221 | 0.11208277998462797 | 0.007417465604015432 |
|     2480    | 0.11734691457792093 |  0.001992086149172291 | 0.11179574512991071 | 0.00711830640489618  |
|     3200    | 0.11505386252353525 |  0.001855360583970836 | 0.11205434561761847 | 0.006871591546152986 |
+-------------+---------------------+-----------------------+---------------------+----------------------+


Boostrap metrics, sample 20 results:
+---------------------+---------------------+--------------------------------+
|  mean_squared_error | mean_absolute_error | mean_absolute_percentage_error |
+---------------------+---------------------+--------------------------------+
| 0.10011973983768101 | 0.20309210156134214 |       472909708299368.8        |
| 0.07889047609638247 |  0.1831025267919851 |       487045566057659.94       |
| 0.09855500120721822 | 0.20051001199189158 |       476156265543622.3        |
| 0.08768507918678875 |  0.1895151871050613 |       484847473044894.6        |
| 0.09115078206413058 | 0.19281151950941158 |       480552451569152.9        |
| 0.11546212421426941 | 0.21863459016758885 |       463462046103627.44       |
| 0.11313314899690145 | 0.21736743349579946 |       462937813987883.4        |
| 0.09791763532644758 | 0.20217415362864094 |       473827114501920.94       |
| 0.08261645249963108 |  0.1868062693919383 |       484061124871278.4        |
| 0.07121618525693156 |  0.1756950415920786 |       493669738575102.9        |
|  0.0964450979659851 | 0.19935925823313155 |       475632033427878.25       |
| 0.08881527473312495 | 0.19200997448973978 |       482387263974257.25       |
| 0.08261645249963108 |  0.1868062693919383 |       484061124871278.4        |
| 0.10035941258870179 |  0.2033540081156583 |       473564998444048.94       |
| 0.09631169514621288 | 0.19941745968964625 |       476287323572558.3        |
| 0.09494182684885588 | 0.19666076575065156 |       478092242498515.5        |
| 0.09498302839862777 | 0.19677716866368097 |       478616474614259.6        |
| 0.10892154466437354 | 0.20985397061350652 |       472546427691707.8        |
| 0.07508896351855206 | 0.17907867618120096 |       488588368925745.1        |
| 0.09287345996871896 | 0.19612112728529596 |       480582345048300.0        |
+---------------------+---------------------+--------------------------------+

