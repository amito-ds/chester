Full report to analyze my data:

Data information:
Data Information Report
Problem Type: Regression
Target Variable: target
Feature Types: {'numeric': [], 'boolean': [], 'text': [], 'categorical': ['landing_page', 'country'], 'time': [], 'id': []}
Loss Function: R squared
Evaluation Metrics: ['R2', 'MSE', 'MAE', 'MAPE']
Optional Models: {'linear', 'catboost', 'baseline-median', 'baseline-average'}


features engineering process for the data:
** model pre analysis report:
Feature stats:
            col # unique # missing  max   min  avg   std             CI  \
0  target_label        3         0  1.0  -1.0  0.0  0.34  (-0.01, 0.01)   

  median       top_vals    bottom_vals  
0    0.0  1.0,-0.0,-1.0  -1.0,-0.0,1.0  

top 50 with lowest partial pvalue for categorical feat based on chi square:
[('landing_page', 5.995506954860664e-121), ('country', 0.2851901497217846)]

Training models and choosing the best one
Model results compared - showing the best out of each type after CV & HP tuning: 
+-------+-----------------------+---------------------+---------------------+--------------------------------+
|  type |         model         |  mean_squared_error | mean_absolute_error | mean_absolute_percentage_error |
+-------+-----------------------+---------------------+---------------------+--------------------------------+
|  test |     BaselineModel     | 0.11174999999999999 | 0.11174999999999999 |      0.11174999999999999       |
|  test |     CatboostModel     | 0.10018022797358735 | 0.19688734664782662 |       436672058316175.5        |
|  test | LinearRegressionModel | 0.10005755994055272 | 0.19630506072364792 |       433989736066083.3        |
| train |     BaselineModel     | 0.11174999999999999 | 0.11174999999999999 |      0.11174999999999999       |
| train |     CatboostModel     | 0.09975789465216192 | 0.19622395456090894 |       434490942397906.1        |
| train | LinearRegressionModel | 0.09975901501280267 | 0.19592312052988292 |       432888695393946.4        |
+-------+-----------------------+---------------------+---------------------+--------------------------------+


Post model analysis - analyzing results of the chosen model: 
Learning curve by training examples
+-------------+---------------------+-----------------------+---------------------+----------------------+
| train_sizes |  train_scores_mean  |    train_scores_std   |   test_scores_mean  |   test_scores_std    |
+-------------+---------------------+-----------------------+---------------------+----------------------+
|     320     | 0.09022429714659966 |  0.020849243963640785 |  0.0867139252955478 | 0.014478399359988906 |
|     1040    | 0.09966787125214593 |  0.007706939361090329 | 0.09986320963599633 | 0.012715185500360071 |
|     1760    | 0.10288834949962715 | 0.0053363695454034365 | 0.10150623689540275 | 0.013150540719593354 |
|     2480    | 0.10386723283356754 |  0.004483314914493993 | 0.10186373302538751 | 0.01452157936500313  |
|     3200    |  0.1060636980681153 |  0.003363763710455336 | 0.10183613163216734 | 0.013756737293607275 |
+-------------+---------------------+-----------------------+---------------------+----------------------+


Boostrap metrics, sample 20 results:
+---------------------+---------------------+--------------------------------+
|  mean_squared_error | mean_absolute_error | mean_absolute_percentage_error |
+---------------------+---------------------+--------------------------------+
| 0.15302697451313763 | 0.24968284469979574 |       401433440144518.94       |
| 0.09059547372583104 | 0.18689306851395254 |       439111930467601.94       |
| 0.11447637993946079 | 0.21135568032047147 |       428424531304463.6        |
| 0.11387586166157825 | 0.20961155488270392 |       421109741242091.94       |
| 0.09781541904868823 | 0.19379191173716204 |       431202356879347.2        |
| 0.12102791021051473 | 0.21776700910391994 |       419834410164367.06       |
| 0.12234828016414745 | 0.22014638336534403 |       428295305461518.5        |
| 0.11380605080495591 | 0.21039868391687722 |       425333944118335.8        |
| 0.12200028012601362 | 0.21842056989118028 |       420435005364933.25       |
| 0.13269877089186843 | 0.22953909615547732 |       412856860462007.1        |
| 0.11783710562619382 | 0.21440775147546426 |       423071819982497.44       |
| 0.10923093173429152 | 0.20605328399560327 |       427508457070878.0        |
| 0.10925237927311919 |  0.2061807716429125 |       428030042626627.8        |
| 0.13343474045311926 |  0.2296715227754119 |       411545393099707.6        |
| 0.09124629260201508 | 0.18850681758658425 |       445553110270368.6        |
| 0.09905571253514665 | 0.19627449656450402 |       440380417841197.94       |
| 0.09065365754765926 | 0.18669638499778224 |       437981774885131.2        |
| 0.11714962165984472 | 0.21429568707393215 |       424517066161832.2        |
|  0.1294301768795484 | 0.22613370794778093 |       416033727688816.6        |
| 0.12245036076651779 | 0.21947413728573684 |       424535921651483.06       |
+---------------------+---------------------+--------------------------------+

