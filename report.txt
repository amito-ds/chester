Full report to analyze my data:

Data information:
Data Information Report
Problem Type: Regression
Target Variable: target
Feature Types: {'numeric': [], 'boolean': [], 'text': [], 'categorical': ['landing_page', 'country'], 'time': [], 'id': []}
Loss Function: R squared
Evaluation Metrics: ['R2', 'MSE', 'MAE', 'MAPE']
Optional Models: {'baseline-average', 'linear', 'catboost', 'baseline-median'}


features engineering process for the data:
** model pre analysis report:
Feature stats:
            col # unique # missing  max   min    avg   std             CI  \
0  target_label        3         0  1.0  -1.0  -0.01  0.35  (-0.02, -0.0)   

  median       top_vals    bottom_vals  
0    0.0  1.0,-0.0,-1.0  -1.0,-0.0,1.0  

top 50 with lowest partial pvalue for categorical feat based on chi square:
[('landing_page', 1.670987905265905e-125), ('country', 0.9036118626899697)]

Training models and choosing the best one
Model results compared - showing the best out of each type after CV & HP tuning: 
+-------+-----------------------+---------------------+---------------------+--------------------------------+
|  type |         model         |  mean_squared_error | mean_absolute_error | mean_absolute_percentage_error |
+-------+-----------------------+---------------------+---------------------+--------------------------------+
|  test |     BaselineModel     | 0.11673496093750002 | 0.12441359375000001 |       34735419500978.617       |
|  test |     CatboostModel     |  0.1040116086072375 | 0.20244162088516182 |       442676659030077.25       |
|  test | LinearRegressionModel | 0.11673496093750002 | 0.12441359375000001 |       34735419500978.617       |
| train |     BaselineModel     | 0.11666660156250001 |   0.1243989453125   |        34823380431200.7        |
| train |     CatboostModel     | 0.10370854920480724 | 0.20215374532730462 |       442074572401871.3        |
| train | LinearRegressionModel | 0.11666660156250001 |   0.1243989453125   |        34823380431200.7        |
+-------+-----------------------+---------------------+---------------------+--------------------------------+


Post model analysis - analyzing results of the chosen model: 
Top 100 Feature importance (in %, 100 = the most important one):
{'index_landing_page': 100, 'index_country': 1}

Learning curve by training examples
+-------------+---------------------+-----------------------+---------------------+-----------------------+
| train_sizes |  train_scores_mean  |    train_scores_std   |   test_scores_mean  |    test_scores_std    |
+-------------+---------------------+-----------------------+---------------------+-----------------------+
|     320     | 0.10806802628292773 |  0.01261952527588486  | 0.08816242529405316 |  0.009707233444446127 |
|     1040    | 0.11017996449161757 |  0.009258634916331592 |  0.1029617278113402 |  0.008717085972288983 |
|     1760    | 0.11421007153318938 |  0.003346250825599468 | 0.10622689497801636 | 0.0070250371623187995 |
|     2480    | 0.11242283409815443 |  0.00265095044366196  | 0.10697732206911084 |  0.00714807324146489  |
|     3200    |  0.1110460097289562 | 0.0019800786575820324 | 0.10741710507319416 |  0.006410523370285989 |
+-------------+---------------------+-----------------------+---------------------+-----------------------+


Boostrap metrics, sample 20 results:
+---------------------+---------------------+--------------------------------+
|  mean_squared_error | mean_absolute_error | mean_absolute_percentage_error |
+---------------------+---------------------+--------------------------------+
| 0.12505016667358781 | 0.22389439933179012 |       428250813515612.06       |
| 0.14038605177424196 | 0.23895969487290786 |       416355010980133.5        |
| 0.11281778199504836 | 0.21197141393260946 |       436080152201972.75       |
| 0.10554835357687513 |  0.2040719390308674 |       438985260448798.06       |
| 0.13325688117919807 | 0.23143670769743516 |       420797912506766.4        |
|  0.1407083052016403 | 0.23951369040829817 |       418280878040868.8        |
| 0.12508273592548408 | 0.22364774451000977 |       426892659189954.8        |
| 0.10495416643493442 |  0.2036354076207102 |       438462902507556.94       |
| 0.10351822036725808 |  0.2012271497774529 |       442253233988420.5        |
| 0.10093814598799689 |  0.2000184320358852 |       442723343014372.8        |
| 0.10494814556520979 | 0.20387737222791588 |       439717377833907.5        |
| 0.12072059421325498 | 0.21979397336255496 |       430956784149343.7        |
| 0.10516140233974802 | 0.20367715672335288 |       438076770302083.6        |
| 0.13974961469831218 |  0.2386967035546393 |       416853869428997.7        |
| 0.11761728283024324 | 0.21623882268624522 |       432883428530736.6        |
| 0.10121063326152491 |  0.2004172959334569 |       443995555121200.9        |
|  0.0976541345844709 | 0.19646444816930803 |       445192775654108.5        |
| 0.12531857951868633 |  0.2242153566500778 |       429118489505234.75       |
| 0.10469415218094612 |  0.2018626004590233 |       442113118574825.44       |
| 0.09385518677938479 | 0.19287022136975332 |       448976674943249.7        |
+---------------------+---------------------+--------------------------------+

